{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_size = 32\n",
    "folder_path = \"images/\"\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "no_of_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_images(folder_path, picture_size, color_mode='grayscale'):\n",
    "    print(f\"Preprocessing images in: {folder_path}\")\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Error: The path {folder_path} does not exist.\")\n",
    "        print(f\"Current working directory: {os.getcwd()}\")\n",
    "        print(f\"Contents of current directory: {os.listdir('.')}\")\n",
    "        raise FileNotFoundError(f\"The path {folder_path} does not exist\")\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted([d for d in os.listdir(folder_path) if d != \"disgust\" and os.path.isdir(os.path.join(folder_path, d))])\n",
    "    \n",
    "    print(f\"Found the following classes (excluding 'disgust'): {class_names}\")\n",
    "    \n",
    "\n",
    "    total_images = sum(len(os.listdir(os.path.join(folder_path, class_name))) \n",
    "                       for class_name in class_names)\n",
    "    \n",
    "\n",
    "    pbar = tqdm(total=total_images, desc=\"Processing images\")\n",
    "    \n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            img = load_img(img_path, target_size=(picture_size, picture_size), color_mode=color_mode)\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(class_name)\n",
    "            pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    print(\"Converting to numpy array and normalizing...\")\n",
    "    images = np.array(images, dtype='float32') / 255.0\n",
    "    \n",
    "    print(\"Encoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    labels_encoded = le.fit_transform(labels)\n",
    "    labels_categorical = to_categorical(labels_encoded)\n",
    "    \n",
    "    return images, labels_categorical, le.classes_\n",
    "\n",
    "\n",
    "folder_path = \"images\"\n",
    "picture_size = 32\n",
    "train_path = os.path.join(folder_path, \"train\")\n",
    "X_train, y_train, class_names = preprocess_images(train_path, picture_size)\n",
    "val_path = os.path.join(folder_path, \"validation\")\n",
    "X_val, y_val, _ = preprocess_images(val_path, picture_size)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Validation data shape: {X_val.shape}\")\n",
    "print(f\"Validation labels shape: {y_val.shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "def create_improved_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3,3), padding='same', input_shape=input_shape, kernel_regularizer=l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Conv2D(128, (3,3), padding='same', kernel_regularizer=l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256, kernel_regularizer=l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(512, kernel_regularizer=l2(0.0001)),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "model = create_improved_model(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=100,  \n",
    "    batch_size=32,  \n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
